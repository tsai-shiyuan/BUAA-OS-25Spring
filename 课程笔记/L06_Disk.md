# 磁盘存储管理

我们每天都在和文件打交道，这些文件都存储在哪里呢？主要是磁盘。这一章我们就来深入了解计算机是如何管理这些“数据仓库”的。

## 磁盘的工作原理

### 机械磁盘 (HDD, Hard Disk Drive)

![截屏2025-05-13 14.44.37](./images_buaa/%E6%88%AA%E5%B1%8F2025-05-13%2014.44.37.png)

![截屏2025-05-13 14.45.16](./images_buaa/%E6%88%AA%E5%B1%8F2025-05-13%2014.45.16.png)

从操作系统的视角来看: 磁盘被抽象成了大小均为512B的逻辑块序列

从磁盘来看: 一维逻辑块数组按顺序映射到磁盘的扇区

通过磁盘控制器将逻辑块号翻译成“盘片+磁道+扇区”的三元组信息

![截屏2025-05-13 14.51.52](./images_buaa/%E6%88%AA%E5%B1%8F2025-05-13%2014.51.52.png)

磁盘访问时间:

1. 寻道时间: 包括启动磁盘的时间 $s$ 与磁头移动 $n$ 条磁道的时间，$T_s = m\times n + s$
2. 旋转延迟: 转速为 $r$ 转/分，则 $T_r = 1/2r$ (平均转半圈)
3. 传输时间: 把数据从磁盘读出/向磁盘写入数据所经历的时间，若读 $b$ 个字节，转速为 $r$ ，磁道上的字节数为 $N$，则 $T_t = \frac{b}{rN}$

寻道时间 (因为是机械运动，而且到一个还要刹车) 和旋转延迟在总访问时间中占比大

![截屏2025-05-13 14.45.36](./images_buaa/%E6%88%AA%E5%B1%8F2025-05-13%2014.45.36.png)

### 磁盘调度算法

当多个I/O请求等待访问磁盘时，用磁盘调度算法决定处理这些请求的顺序，以优化磁盘性能。算法的评价标准是效率兼公平

#### 先来先服务 (FCFS)

- 按访问请求到达的先后次序服务
- 效率不高，可能导致磁头在盘面上来回大幅度移动

#### 最短寻道时间优先 (SSTF)

- 优先选择距当前磁头最近的访问请求进行服务
- 可能造成某些请求长期等待得不到服务，不公平

**扫描算法 (SCAN):**

- 类似电梯调度的Look算法，但是要到达边界再转向
- 磁头按一个方向移动，在移动过程中对遇到请求便进行服务

**循环扫描算法 (C-SCAN):**

- 移动臂到达最后一个柱面后，立即带动读写磁头快速返回到0号柱面。相当于电梯只接上行的乘客

**查看扫描算法 (LOOK):**

- 类似电梯的Look，不一定到达边界再转向
- 同理衍生出循环查看扫描算法 (C-LOOK)

**N-Step-SCAN:**

- 磁臂粘着现象: 少数进程高频访问某个磁道导致其他请求饥饿
- N-Step-SCAN 算法的工作原理:
  - **请求队列分组: **将磁盘I/O请求队列分成若干个长度固定为N的子队列
  - **子队列间FCFS**
  - **子队列内SCAN**
- N-Step-SCAN可以避免磁壁粘着现象，因为总能服务到其他磁道

### 固态硬盘 (SSD, Solid-State Drive)

闪存芯片



固态硬盘的数据以page为单位读写



## 磁盘的可靠性

理想的磁盘是大容量、速度快、可靠的。David Patterson教授等提出 RAID (Redundant Array of Inexpensive Disks) 技术，即廉价冗余磁盘阵列，使用多个磁盘来实现具有上述性质的磁盘系统。

### RAID Level 0: Striping

![截屏2025-05-14 13.18.55](./images_buaa/%E6%88%AA%E5%B1%8F2025-05-14%2013.18.55.png)

- 思想: **stripe** blocks across the disks，我们把位于同一行的数据块称为一个条带 (stripe)

- 不同的数据块分布在不同磁盘上，所以多个磁盘可以并行处理请求

- 另外，还可以把几个数据块组成一个chunk，再将chunk轮流排布

![截屏2025-05-14 13.23.43](./images_buaa/%E6%88%AA%E5%B1%8F2025-05-14%2013.23.43.png)

- RAID 0 不具备容错能力

### RAID Level 1: Mirroring

![截屏2025-05-14 13.40.45](./images_buaa/%E6%88%AA%E5%B1%8F2025-05-14%2013.40.45.png)

- 思想: for each logical block, the RAID keeps two physical copies of it
- 读的时候可以读任意拷贝，写的时候两个拷贝都要写
- 可以容忍一个磁盘故障 (disk failure)。实际上只要镜像有一个不失效，最多可以坏 N/2 个磁盘，但默认只容错一次，否则风险不可控
- **consistent-update problem:**
  - 假设写完 Disk 0 的时候断电了，此时 Disk 1 还没写完，这样造成两个拷贝数据不一致
  - 解决方法是使用写前日志 (write-ahead log)，即在 RAID 执行操作之前先记录下将要做什么，断电恢复时可以重新执行未完成的操作。大多数 RAID 硬件包含一小块非易失 RAM 来执行日志操作。

### RAID Level 4: Saving Space With Parity

![截屏2025-05-14 14.10.33](./images_buaa/%E6%88%AA%E5%B1%8F2025-05-14%2014.10.33.png)

- 为磁盘阵列添加冗余的新方法: 奇偶校验 (parity)，例如: 采用 XOR 运算，所有的C与P的异或值应该始终为0，这个规律可以用于恢复磁盘

  ![截屏2025-05-14 14.12.44](./images_buaa/%E6%88%AA%E5%B1%8F2025-05-14%2014.12.44.png)

### RAID Level 5: Rotating Parity

![截屏2025-05-14 14.23.59](./images_buaa/%E6%88%AA%E5%B1%8F2025-05-14%2014.23.59.png)

- RAID 5 和 RAID 4 相似，不过 RAID 5 把 parity block 分散到每个磁盘上

### RAID比较

![截屏2025-05-14 14.33.00](./images_buaa/%E6%88%AA%E5%B1%8F2025-05-14%2014.33.00.png)
